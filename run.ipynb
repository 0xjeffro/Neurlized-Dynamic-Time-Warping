{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/datasets/process.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train.append(test, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "from models.DTWRNN import Model as DTWRNN_Model\n",
    "from utils.evaluators import compute_acc, compute_ave_batch_loss\n",
    "from datasets.process import ecg5000_reading\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "shaplets = torch.load('datasets/ECG5000/shaplets/shaplets_{10.10.10.10.10}_{random_select}.pt')\n",
    "\n",
    "\n",
    "X, Y = ecg5000_reading()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=RANDOM_SEED, stratify=Y)\n",
    "X_verify, X_test, Y_verify, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=RANDOM_SEED, stratify=Y_test)\n",
    "\n",
    "class Kaggle_ECG(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.length = len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "ds_train = Kaggle_ECG(X_train, Y_train)\n",
    "ds_verify = Kaggle_ECG(X_verify, Y_verify)\n",
    "ds_test = Kaggle_ECG(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_n_epoch = 80\n",
    "_batch_size = 200\n",
    "train_data_loader = DataLoader(dataset=ds_train, batch_size=_batch_size, shuffle=True)\n",
    "verify_data_loader = DataLoader(dataset=ds_verify, batch_size=_batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(dataset=ds_test, batch_size=_batch_size, shuffle=True)\n",
    "\n",
    "model = DTWRNN_Model(shaplets=shaplets.reshape(50, 50, 1), batch_size=_batch_size)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŸðŸŒŸðŸŒŸ Zero-shot Result: \tAccuracy: 0.769000 \tPrecision: 0.472112 \tF1-score: 0.478949\n",
      "Epoch: 0 \tTraining Loss: 152.162183 \tValidation Loss: 118.338417  \tTesting Loss: 116.794966  \n",
      "\t\tAccuracy: 0.877000 \tPrecision: 0.548038 \tF1-score: 0.559454\n",
      "Epoch: 1 \tTraining Loss: 107.271086 \tValidation Loss: 96.367968  \tTesting Loss: 91.829954  \n",
      "\t\tAccuracy: 0.904000 \tPrecision: 0.594831 \tF1-score: 0.595537\n",
      "Epoch: 2 \tTraining Loss: 89.826548 \tValidation Loss: 84.621608  \tTesting Loss: 79.287964  \n",
      "\t\tAccuracy: 0.921000 \tPrecision: 0.640338 \tF1-score: 0.639345\n",
      "Epoch: 3 \tTraining Loss: 80.096590 \tValidation Loss: 77.704819  \tTesting Loss: 70.996743  \n",
      "\t\tAccuracy: 0.924000 \tPrecision: 0.674153 \tF1-score: 0.658400\n",
      "Epoch: 4 \tTraining Loss: 73.077493 \tValidation Loss: 73.062605  \tTesting Loss: 66.439807  \n",
      "\t\tAccuracy: 0.929000 \tPrecision: 0.709430 \tF1-score: 0.674438\n",
      "Epoch: 5 \tTraining Loss: 68.072580 \tValidation Loss: 68.893248  \tTesting Loss: 62.355544  \n",
      "\t\tAccuracy: 0.932000 \tPrecision: 0.719276 \tF1-score: 0.678445\n",
      "Epoch: 6 \tTraining Loss: 63.829421 \tValidation Loss: 66.083345  \tTesting Loss: 59.528424  \n",
      "\t\tAccuracy: 0.933000 \tPrecision: 0.728491 \tF1-score: 0.671247\n",
      "Epoch: 7 \tTraining Loss: 60.568002 \tValidation Loss: 64.214698  \tTesting Loss: 57.315128  \n",
      "\t\tAccuracy: 0.934000 \tPrecision: 0.760538 \tF1-score: 0.681431\n",
      "Epoch: 8 \tTraining Loss: 57.967522 \tValidation Loss: 62.038907  \tTesting Loss: 55.837083  \n",
      "\t\tAccuracy: 0.936000 \tPrecision: 0.775100 \tF1-score: 0.686442\n",
      "Epoch: 9 \tTraining Loss: 55.714233 \tValidation Loss: 60.671888  \tTesting Loss: 54.678583  \n",
      "\t\tAccuracy: 0.936000 \tPrecision: 0.775100 \tF1-score: 0.686442\n",
      "Epoch: 10 \tTraining Loss: 53.422868 \tValidation Loss: 59.657122  \tTesting Loss: 53.856792  \n",
      "\t\tAccuracy: 0.937000 \tPrecision: 0.782727 \tF1-score: 0.688488\n",
      "Epoch: 11 \tTraining Loss: 51.802152 \tValidation Loss: 58.464420  \tTesting Loss: 52.297516  \n",
      "\t\tAccuracy: 0.937000 \tPrecision: 0.782727 \tF1-score: 0.688488\n",
      "Epoch: 12 \tTraining Loss: 50.127521 \tValidation Loss: 57.347124  \tTesting Loss: 51.520729  \n",
      "\t\tAccuracy: 0.939000 \tPrecision: 0.783598 \tF1-score: 0.689376\n",
      "Epoch: 13 \tTraining Loss: 48.335026 \tValidation Loss: 56.402638  \tTesting Loss: 50.571853  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.793493 \tF1-score: 0.692775\n",
      "Epoch: 14 \tTraining Loss: 46.930282 \tValidation Loss: 55.479372  \tTesting Loss: 49.712585  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.786206 \tF1-score: 0.690091\n",
      "Epoch: 15 \tTraining Loss: 45.725962 \tValidation Loss: 55.048949  \tTesting Loss: 49.386522  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.786206 \tF1-score: 0.690091\n",
      "Epoch: 16 \tTraining Loss: 44.445632 \tValidation Loss: 54.239406  \tTesting Loss: 48.890404  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.801929 \tF1-score: 0.701384\n",
      "Epoch: 17 \tTraining Loss: 43.436334 \tValidation Loss: 53.748683  \tTesting Loss: 48.356715  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.801929 \tF1-score: 0.701384\n",
      "Epoch: 18 \tTraining Loss: 42.538037 \tValidation Loss: 53.208664  \tTesting Loss: 47.687977  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.801929 \tF1-score: 0.701384\n",
      "Epoch: 19 \tTraining Loss: 41.675888 \tValidation Loss: 52.967634  \tTesting Loss: 47.541406  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.808944 \tF1-score: 0.704152\n",
      "Epoch: 20 \tTraining Loss: 41.011543 \tValidation Loss: 52.879876  \tTesting Loss: 47.515295  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.802310 \tF1-score: 0.701843\n",
      "Epoch: 21 \tTraining Loss: 40.236800 \tValidation Loss: 52.107108  \tTesting Loss: 46.985422  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.810428 \tF1-score: 0.705445\n",
      "Epoch: 22 \tTraining Loss: 39.728879 \tValidation Loss: 52.000908  \tTesting Loss: 46.847988  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.802310 \tF1-score: 0.701843\n",
      "Epoch: 23 \tTraining Loss: 38.789776 \tValidation Loss: 51.827992  \tTesting Loss: 46.669868  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.809816 \tF1-score: 0.705042\n",
      "Epoch: 24 \tTraining Loss: 38.218934 \tValidation Loss: 51.571336  \tTesting Loss: 46.140519  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.810805 \tF1-score: 0.705904\n",
      "Epoch: 25 \tTraining Loss: 37.669588 \tValidation Loss: 51.477344  \tTesting Loss: 46.068860  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.810309 \tF1-score: 0.705473\n",
      "Epoch: 26 \tTraining Loss: 37.086880 \tValidation Loss: 51.088161  \tTesting Loss: 45.992881  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.802803 \tF1-score: 0.702274\n",
      "Epoch: 27 \tTraining Loss: 36.489155 \tValidation Loss: 50.784011  \tTesting Loss: 45.749959  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.810309 \tF1-score: 0.705473\n",
      "Epoch: 28 \tTraining Loss: 36.026263 \tValidation Loss: 50.468876  \tTesting Loss: 45.385216  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.802803 \tF1-score: 0.702274\n",
      "Epoch: 29 \tTraining Loss: 35.556603 \tValidation Loss: 50.355195  \tTesting Loss: 45.157481  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.808439 \tF1-score: 0.710787\n",
      "Epoch: 30 \tTraining Loss: 35.128624 \tValidation Loss: 49.995504  \tTesting Loss: 45.267119  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.808439 \tF1-score: 0.710787\n",
      "Epoch: 31 \tTraining Loss: 34.522669 \tValidation Loss: 49.865664  \tTesting Loss: 44.755619  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.808937 \tF1-score: 0.711219\n",
      "Epoch: 32 \tTraining Loss: 34.073347 \tValidation Loss: 49.718004  \tTesting Loss: 44.720119  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.808937 \tF1-score: 0.711219\n",
      "Epoch: 33 \tTraining Loss: 33.672545 \tValidation Loss: 49.739522  \tTesting Loss: 44.425769  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.824176 \tF1-score: 0.717786\n",
      "Epoch: 34 \tTraining Loss: 33.256372 \tValidation Loss: 49.234427  \tTesting Loss: 43.991522  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.797334 \tF1-score: 0.700200\n",
      "Epoch: 35 \tTraining Loss: 32.856447 \tValidation Loss: 49.020676  \tTesting Loss: 44.160446  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.804368 \tF1-score: 0.703805\n",
      "Epoch: 36 \tTraining Loss: 32.564204 \tValidation Loss: 48.833784  \tTesting Loss: 43.918442  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.811874 \tF1-score: 0.707003\n",
      "Epoch: 37 \tTraining Loss: 32.084157 \tValidation Loss: 48.590649  \tTesting Loss: 43.912959  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.811874 \tF1-score: 0.707003\n",
      "Epoch: 38 \tTraining Loss: 31.795799 \tValidation Loss: 48.261209  \tTesting Loss: 43.505937  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.811874 \tF1-score: 0.707003\n",
      "Epoch: 39 \tTraining Loss: 31.450803 \tValidation Loss: 48.106781  \tTesting Loss: 43.342070  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.811874 \tF1-score: 0.707003\n",
      "Epoch: 40 \tTraining Loss: 31.046905 \tValidation Loss: 48.047099  \tTesting Loss: 43.546635  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.817208 \tF1-score: 0.715574\n",
      "Epoch: 41 \tTraining Loss: 30.701021 \tValidation Loss: 48.083263  \tTesting Loss: 43.538234  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.814832 \tF1-score: 0.706055\n",
      "Epoch: 42 \tTraining Loss: 30.441016 \tValidation Loss: 47.928972  \tTesting Loss: 43.140059  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.811874 \tF1-score: 0.707003\n",
      "Epoch: 43 \tTraining Loss: 30.041218 \tValidation Loss: 47.482225  \tTesting Loss: 43.107835  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.789373 \tF1-score: 0.698426\n",
      "Epoch: 44 \tTraining Loss: 29.887240 \tValidation Loss: 47.541845  \tTesting Loss: 42.951481  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.778874 \tF1-score: 0.696060\n",
      "Epoch: 45 \tTraining Loss: 29.552331 \tValidation Loss: 47.568423  \tTesting Loss: 42.812175  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.771333 \tF1-score: 0.692745\n",
      "Epoch: 46 \tTraining Loss: 29.220812 \tValidation Loss: 47.592448  \tTesting Loss: 42.912525  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.778874 \tF1-score: 0.696060\n",
      "Epoch: 47 \tTraining Loss: 29.041519 \tValidation Loss: 47.271712  \tTesting Loss: 42.440110  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.778874 \tF1-score: 0.696060\n",
      "Epoch: 48 \tTraining Loss: 28.814802 \tValidation Loss: 47.275224  \tTesting Loss: 42.425418  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.781832 \tF1-score: 0.695113\n",
      "Epoch: 49 \tTraining Loss: 28.541977 \tValidation Loss: 47.230321  \tTesting Loss: 42.586105  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.789373 \tF1-score: 0.698426\n",
      "Epoch: 50 \tTraining Loss: 28.378169 \tValidation Loss: 47.100249  \tTesting Loss: 41.933001  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.771333 \tF1-score: 0.692745\n",
      "Epoch: 51 \tTraining Loss: 28.041633 \tValidation Loss: 47.124072  \tTesting Loss: 41.959934  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.769707 \tF1-score: 0.689706\n",
      "Epoch: 52 \tTraining Loss: 27.819865 \tValidation Loss: 46.797989  \tTesting Loss: 41.870493  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.762166 \tF1-score: 0.686392\n",
      "Epoch: 53 \tTraining Loss: 27.699239 \tValidation Loss: 46.602861  \tTesting Loss: 41.686092  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.775208 \tF1-score: 0.692083\n",
      "Epoch: 54 \tTraining Loss: 27.491458 \tValidation Loss: 46.410511  \tTesting Loss: 41.198453  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.771333 \tF1-score: 0.692745\n",
      "Epoch: 55 \tTraining Loss: 27.211210 \tValidation Loss: 46.577683  \tTesting Loss: 41.467424  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.775208 \tF1-score: 0.692083\n",
      "Epoch: 56 \tTraining Loss: 27.043504 \tValidation Loss: 46.471662  \tTesting Loss: 41.393897  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.739535 \tF1-score: 0.678577\n",
      "Epoch: 57 \tTraining Loss: 26.839029 \tValidation Loss: 46.573685  \tTesting Loss: 41.472270  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.769697 \tF1-score: 0.689664\n",
      "Epoch: 58 \tTraining Loss: 26.666079 \tValidation Loss: 46.208066  \tTesting Loss: 41.064722  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.750034 \tF1-score: 0.680944\n",
      "Epoch: 59 \tTraining Loss: 26.420668 \tValidation Loss: 46.376740  \tTesting Loss: 41.090532  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.770075 \tF1-score: 0.690121\n",
      "Epoch: 60 \tTraining Loss: 26.362214 \tValidation Loss: 46.365829  \tTesting Loss: 40.678288  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.764956 \tF1-score: 0.695524\n",
      "Epoch: 61 \tTraining Loss: 26.036584 \tValidation Loss: 46.296337  \tTesting Loss: 40.572382  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.781341 \tF1-score: 0.701023\n",
      "Epoch: 62 \tTraining Loss: 25.944664 \tValidation Loss: 46.272538  \tTesting Loss: 40.667730  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.744873 \tF1-score: 0.682611\n",
      "Epoch: 63 \tTraining Loss: 25.738574 \tValidation Loss: 46.398303  \tTesting Loss: 40.915572  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.775830 \tF1-score: 0.698347\n",
      "Epoch: 64 \tTraining Loss: 25.612422 \tValidation Loss: 46.173023  \tTesting Loss: 40.731288  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.765725 \tF1-score: 0.692507\n",
      "Epoch: 65 \tTraining Loss: 25.424720 \tValidation Loss: 46.211452  \tTesting Loss: 40.278142  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.750632 \tF1-score: 0.690699\n",
      "Epoch: 66 \tTraining Loss: 25.317189 \tValidation Loss: 46.141174  \tTesting Loss: 40.309277  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.775454 \tF1-score: 0.697891\n",
      "Epoch: 67 \tTraining Loss: 25.166641 \tValidation Loss: 46.096919  \tTesting Loss: 40.227838  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.803900 \tF1-score: 0.706759\n",
      "Epoch: 68 \tTraining Loss: 25.037297 \tValidation Loss: 46.190003  \tTesting Loss: 40.377995  \n",
      "\t\tAccuracy: 0.953000 \tPrecision: 0.809203 \tF1-score: 0.709745\n",
      "Epoch: 69 \tTraining Loss: 24.887194 \tValidation Loss: 46.153646  \tTesting Loss: 39.932990  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.800248 \tF1-score: 0.709234\n",
      "Epoch: 70 \tTraining Loss: 24.714858 \tValidation Loss: 45.604865  \tTesting Loss: 39.915143  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.788601 \tF1-score: 0.701541\n",
      "Epoch: 71 \tTraining Loss: 24.731024 \tValidation Loss: 45.990140  \tTesting Loss: 39.841762  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.771062 \tF1-score: 0.695910\n",
      "Epoch: 72 \tTraining Loss: 24.388572 \tValidation Loss: 45.917406  \tTesting Loss: 39.717403  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.736102 \tF1-score: 0.681971\n",
      "Epoch: 73 \tTraining Loss: 24.374930 \tValidation Loss: 45.785702  \tTesting Loss: 39.746559  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.800248 \tF1-score: 0.709234\n",
      "Epoch: 74 \tTraining Loss: 24.115288 \tValidation Loss: 45.718073  \tTesting Loss: 39.697930  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.771062 \tF1-score: 0.695910\n",
      "Epoch: 75 \tTraining Loss: 24.066612 \tValidation Loss: 45.811422  \tTesting Loss: 39.634874  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.800248 \tF1-score: 0.709234\n",
      "Epoch: 76 \tTraining Loss: 23.871001 \tValidation Loss: 45.923151  \tTesting Loss: 39.472122  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.767253 \tF1-score: 0.698292\n",
      "Epoch: 77 \tTraining Loss: 23.765179 \tValidation Loss: 45.603927  \tTesting Loss: 39.472040  \n",
      "\t\tAccuracy: 0.953000 \tPrecision: 0.772053 \tF1-score: 0.701144\n",
      "Epoch: 78 \tTraining Loss: 23.806222 \tValidation Loss: 45.967887  \tTesting Loss: 39.518089  \n",
      "\t\tAccuracy: 0.953000 \tPrecision: 0.772053 \tF1-score: 0.701144\n",
      "Epoch: 79 \tTraining Loss: 23.501402 \tValidation Loss: 45.701368  \tTesting Loss: 39.248499  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.757272 \tF1-score: 0.695873\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(_n_epoch):\n",
    "    \n",
    "    if epoch == 0:\n",
    "        acc, prec, f1 = compute_acc(model, test_data_loader, labels=[0, 1, 2, 3, 4])\n",
    "        print('ðŸŒŸðŸŒŸðŸŒŸ Zero-shot Result: \\tAccuracy: {:.6f} \\tPrecision: {:.6f} \\tF1-score: {:.6f}'.format(\n",
    "            acc, prec, f1\n",
    "        ))\n",
    "    \n",
    "    train_loss = 0\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data_t, target = data[0].cuda(), data[1].reshape(_batch_size)\n",
    "        o_ = model(data_t)\n",
    "        loss = criterion(torch.log(o_), target.cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * _batch_size\n",
    "        \n",
    "    epoch_train_loss = train_loss / len(train_data_loader)\n",
    "    \n",
    "    epoch_verify_loss = compute_ave_batch_loss(model, verify_data_loader, criterion)\n",
    "    \n",
    "    epoch_test_loss = compute_ave_batch_loss(model, test_data_loader, criterion)\n",
    "    \n",
    "    acc, prec, f1 = compute_acc(model, test_data_loader, labels=[0, 1, 2, 3, 4])\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}  \\tTesting Loss: {:.6f} '\n",
    "         ' \\n\\t\\tAccuracy: {:.6f} \\tPrecision: {:.6f} \\tF1-score: {:.6f}'.format(\n",
    "        epoch, \n",
    "        epoch_train_loss,\n",
    "        epoch_verify_loss,\n",
    "        epoch_test_loss,\n",
    "        acc, prec, f1\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}