{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b51569-2f1b-47b8-9a44-b659a177f4f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/datasets/process.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train.append(test, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "from models.baselines.LSTM import LSTM_Classification\n",
    "from utils.evaluators import compute_acc, compute_ave_batch_loss\n",
    "from datasets.process import ecg5000_reading\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "X, Y = ecg5000_reading()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=RANDOM_SEED, stratify=Y)\n",
    "X_verify, X_test, Y_verify, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=RANDOM_SEED, stratify=Y_test)\n",
    "\n",
    "class Kaggle_ECG(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.length = len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "ds_train = Kaggle_ECG(X_train, Y_train)\n",
    "ds_verify = Kaggle_ECG(X_verify, Y_verify)\n",
    "ds_test = Kaggle_ECG(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2750e3-7469-4eb7-b629-a1e52045ac44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_n_epoch = 100\n",
    "_batch_size = 200\n",
    "train_data_loader = DataLoader(dataset=ds_train, batch_size=_batch_size, shuffle=True)\n",
    "verify_data_loader = DataLoader(dataset=ds_verify, batch_size=_batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(dataset=ds_test, batch_size=_batch_size, shuffle=True)\n",
    "\n",
    "model = LSTM_Classification(1, hidden_dim=100, target_size=5).cuda()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9597ffe0-6cf8-4807-9ec6-f5e0ed5e0dd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŸðŸŒŸðŸŒŸ Zero-shot Result: \tAccuracy: 0.006000 \tPrecision: 0.004569 \tF1-score: 0.006320\n",
      "Epoch: 0 \tTraining Loss: 297.628411 \tValidation Loss: 239.915972  \tTesting Loss: 241.055274  \n",
      "\t\tAccuracy: 0.832000 \tPrecision: 0.330574 \tF1-score: 0.341671\n",
      "Epoch: 1 \tTraining Loss: 151.561379 \tValidation Loss: 108.549573  \tTesting Loss: 104.929440  \n",
      "\t\tAccuracy: 0.860000 \tPrecision: 0.346937 \tF1-score: 0.350995\n",
      "Epoch: 2 \tTraining Loss: 99.762742 \tValidation Loss: 91.890728  \tTesting Loss: 91.581198  \n",
      "\t\tAccuracy: 0.900000 \tPrecision: 0.356678 \tF1-score: 0.369412\n",
      "Epoch: 3 \tTraining Loss: 89.986581 \tValidation Loss: 85.327096  \tTesting Loss: 83.066421  \n",
      "\t\tAccuracy: 0.909000 \tPrecision: 0.361153 \tF1-score: 0.373080\n",
      "Epoch: 4 \tTraining Loss: 85.053478 \tValidation Loss: 81.425483  \tTesting Loss: 79.172539  \n",
      "\t\tAccuracy: 0.911000 \tPrecision: 0.362000 \tF1-score: 0.373956\n",
      "Epoch: 5 \tTraining Loss: 80.900964 \tValidation Loss: 76.874881  \tTesting Loss: 74.647582  \n",
      "\t\tAccuracy: 0.916000 \tPrecision: 0.364445 \tF1-score: 0.376070\n",
      "Epoch: 6 \tTraining Loss: 74.176927 \tValidation Loss: 66.770129  \tTesting Loss: 65.483667  \n",
      "\t\tAccuracy: 0.922000 \tPrecision: 0.367390 \tF1-score: 0.379017\n",
      "Epoch: 7 \tTraining Loss: 66.186811 \tValidation Loss: 60.109400  \tTesting Loss: 59.937037  \n",
      "\t\tAccuracy: 0.922000 \tPrecision: 0.367032 \tF1-score: 0.378827\n",
      "Epoch: 8 \tTraining Loss: 62.652357 \tValidation Loss: 59.015228  \tTesting Loss: 59.441057  \n",
      "\t\tAccuracy: 0.923000 \tPrecision: 0.367419 \tF1-score: 0.379399\n",
      "Epoch: 9 \tTraining Loss: 60.862858 \tValidation Loss: 55.990348  \tTesting Loss: 56.193000  \n",
      "\t\tAccuracy: 0.924000 \tPrecision: 0.367573 \tF1-score: 0.379639\n",
      "Epoch: 10 \tTraining Loss: 58.322704 \tValidation Loss: 54.299818  \tTesting Loss: 54.338537  \n",
      "\t\tAccuracy: 0.924000 \tPrecision: 0.368270 \tF1-score: 0.380016\n",
      "Epoch: 11 \tTraining Loss: 56.537316 \tValidation Loss: 52.648219  \tTesting Loss: 53.060409  \n",
      "\t\tAccuracy: 0.923000 \tPrecision: 0.367250 \tF1-score: 0.379306\n",
      "Epoch: 12 \tTraining Loss: 54.793738 \tValidation Loss: 51.486406  \tTesting Loss: 52.068604  \n",
      "\t\tAccuracy: 0.926000 \tPrecision: 0.468673 \tF1-score: 0.390386\n",
      "Epoch: 13 \tTraining Loss: 54.152472 \tValidation Loss: 50.693123  \tTesting Loss: 51.081550  \n",
      "\t\tAccuracy: 0.928000 \tPrecision: 0.503213 \tF1-score: 0.400911\n",
      "Epoch: 14 \tTraining Loss: 51.579463 \tValidation Loss: 48.440675  \tTesting Loss: 48.365491  \n",
      "\t\tAccuracy: 0.933000 \tPrecision: 0.531310 \tF1-score: 0.448443\n",
      "Epoch: 15 \tTraining Loss: 50.047201 \tValidation Loss: 47.079785  \tTesting Loss: 48.899325  \n",
      "\t\tAccuracy: 0.938000 \tPrecision: 0.528562 \tF1-score: 0.482641\n",
      "Epoch: 16 \tTraining Loss: 48.095938 \tValidation Loss: 45.407499  \tTesting Loss: 45.740201  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.547556 \tF1-score: 0.482750\n",
      "Epoch: 17 \tTraining Loss: 45.786130 \tValidation Loss: 43.728608  \tTesting Loss: 44.741619  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.538873 \tF1-score: 0.486201\n",
      "Epoch: 18 \tTraining Loss: 45.559500 \tValidation Loss: 42.767779  \tTesting Loss: 44.349266  \n",
      "\t\tAccuracy: 0.944000 \tPrecision: 0.541540 \tF1-score: 0.491943\n",
      "Epoch: 19 \tTraining Loss: 46.848291 \tValidation Loss: 44.865274  \tTesting Loss: 45.871652  \n",
      "\t\tAccuracy: 0.938000 \tPrecision: 0.528956 \tF1-score: 0.467333\n",
      "Epoch: 20 \tTraining Loss: 46.746163 \tValidation Loss: 42.731490  \tTesting Loss: 43.929883  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.540899 \tF1-score: 0.491321\n",
      "Epoch: 21 \tTraining Loss: 46.057183 \tValidation Loss: 43.001105  \tTesting Loss: 43.751894  \n",
      "\t\tAccuracy: 0.944000 \tPrecision: 0.541288 \tF1-score: 0.491776\n",
      "Epoch: 22 \tTraining Loss: 44.039250 \tValidation Loss: 42.070232  \tTesting Loss: 43.384878  \n",
      "\t\tAccuracy: 0.944000 \tPrecision: 0.549880 \tF1-score: 0.488675\n",
      "Epoch: 23 \tTraining Loss: 43.903496 \tValidation Loss: 43.769748  \tTesting Loss: 44.703021  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.542054 \tF1-score: 0.492481\n",
      "Epoch: 24 \tTraining Loss: 43.725537 \tValidation Loss: 41.398278  \tTesting Loss: 44.193507  \n",
      "\t\tAccuracy: 0.942000 \tPrecision: 0.541301 \tF1-score: 0.491285\n",
      "Epoch: 25 \tTraining Loss: 42.477291 \tValidation Loss: 41.346536  \tTesting Loss: 44.190556  \n",
      "\t\tAccuracy: 0.942000 \tPrecision: 0.540386 \tF1-score: 0.490783\n",
      "Epoch: 26 \tTraining Loss: 41.950323 \tValidation Loss: 39.683746  \tTesting Loss: 42.198402  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.541816 \tF1-score: 0.491824\n",
      "Epoch: 27 \tTraining Loss: 41.515087 \tValidation Loss: 41.424122  \tTesting Loss: 41.582261  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.530896 \tF1-score: 0.485084\n",
      "Epoch: 28 \tTraining Loss: 41.938056 \tValidation Loss: 39.946012  \tTesting Loss: 41.076743  \n",
      "\t\tAccuracy: 0.942000 \tPrecision: 0.531307 \tF1-score: 0.469487\n",
      "Epoch: 29 \tTraining Loss: 40.792781 \tValidation Loss: 39.278855  \tTesting Loss: 41.335850  \n",
      "\t\tAccuracy: 0.939000 \tPrecision: 0.526998 \tF1-score: 0.462235\n",
      "Epoch: 30 \tTraining Loss: 40.579313 \tValidation Loss: 38.593004  \tTesting Loss: 41.532648  \n",
      "\t\tAccuracy: 0.944000 \tPrecision: 0.542412 \tF1-score: 0.492364\n",
      "Epoch: 31 \tTraining Loss: 40.959338 \tValidation Loss: 40.083516  \tTesting Loss: 41.092057  \n",
      "\t\tAccuracy: 0.944000 \tPrecision: 0.584094 \tF1-score: 0.507955\n",
      "Epoch: 32 \tTraining Loss: 40.676831 \tValidation Loss: 40.396018  \tTesting Loss: 41.099942  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.584608 \tF1-score: 0.508494\n",
      "Epoch: 33 \tTraining Loss: 39.588361 \tValidation Loss: 38.386009  \tTesting Loss: 41.327749  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.640762 \tF1-score: 0.506712\n",
      "Epoch: 34 \tTraining Loss: 40.251345 \tValidation Loss: 37.536950  \tTesting Loss: 42.511255  \n",
      "\t\tAccuracy: 0.940000 \tPrecision: 0.597403 \tF1-score: 0.486677\n",
      "Epoch: 35 \tTraining Loss: 39.349887 \tValidation Loss: 38.356807  \tTesting Loss: 41.797997  \n",
      "\t\tAccuracy: 0.941000 \tPrecision: 0.582777 \tF1-score: 0.506652\n",
      "Epoch: 36 \tTraining Loss: 40.309571 \tValidation Loss: 39.363665  \tTesting Loss: 43.188212  \n",
      "\t\tAccuracy: 0.944000 \tPrecision: 0.613146 \tF1-score: 0.534050\n",
      "Epoch: 37 \tTraining Loss: 42.179162 \tValidation Loss: 43.872359  \tTesting Loss: 46.575736  \n",
      "\t\tAccuracy: 0.941000 \tPrecision: 0.589821 \tF1-score: 0.503662\n",
      "Epoch: 38 \tTraining Loss: 45.763993 \tValidation Loss: 41.504971  \tTesting Loss: 44.141276  \n",
      "\t\tAccuracy: 0.942000 \tPrecision: 0.578158 \tF1-score: 0.510509\n",
      "Epoch: 39 \tTraining Loss: 41.278792 \tValidation Loss: 39.273823  \tTesting Loss: 40.944688  \n",
      "\t\tAccuracy: 0.940000 \tPrecision: 0.582905 \tF1-score: 0.503385\n",
      "Epoch: 40 \tTraining Loss: 39.416621 \tValidation Loss: 39.123644  \tTesting Loss: 40.547091  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.620860 \tF1-score: 0.520510\n",
      "Epoch: 41 \tTraining Loss: 39.151186 \tValidation Loss: 39.187236  \tTesting Loss: 39.121420  \n",
      "\t\tAccuracy: 0.944000 \tPrecision: 0.582896 \tF1-score: 0.508964\n",
      "Epoch: 42 \tTraining Loss: 38.395752 \tValidation Loss: 38.037267  \tTesting Loss: 38.258938  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.623932 \tF1-score: 0.526712\n",
      "Epoch: 43 \tTraining Loss: 37.820684 \tValidation Loss: 40.154099  \tTesting Loss: 40.665413  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.624107 \tF1-score: 0.547685\n",
      "Epoch: 44 \tTraining Loss: 37.951150 \tValidation Loss: 37.907885  \tTesting Loss: 38.922564  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.665502 \tF1-score: 0.548145\n",
      "Epoch: 45 \tTraining Loss: 37.489298 \tValidation Loss: 37.178847  \tTesting Loss: 37.739764  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.656304 \tF1-score: 0.540288\n",
      "Epoch: 46 \tTraining Loss: 38.017594 \tValidation Loss: 37.042477  \tTesting Loss: 38.880260  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.602937 \tF1-score: 0.512296\n",
      "Epoch: 47 \tTraining Loss: 36.973205 \tValidation Loss: 36.831256  \tTesting Loss: 37.346155  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.612728 \tF1-score: 0.530627\n",
      "Epoch: 48 \tTraining Loss: 36.590752 \tValidation Loss: 37.058130  \tTesting Loss: 38.098749  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.667683 \tF1-score: 0.553445\n",
      "Epoch: 49 \tTraining Loss: 36.528018 \tValidation Loss: 36.605093  \tTesting Loss: 36.972467  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.596865 \tF1-score: 0.528680\n",
      "Epoch: 50 \tTraining Loss: 37.398350 \tValidation Loss: 36.560044  \tTesting Loss: 37.509490  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.603541 \tF1-score: 0.529565\n",
      "Epoch: 51 \tTraining Loss: 37.014761 \tValidation Loss: 37.219469  \tTesting Loss: 37.764674  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.600981 \tF1-score: 0.523832\n",
      "Epoch: 52 \tTraining Loss: 36.839640 \tValidation Loss: 36.229502  \tTesting Loss: 38.135327  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.814861 \tF1-score: 0.602309\n",
      "Epoch: 53 \tTraining Loss: 36.035170 \tValidation Loss: 36.133299  \tTesting Loss: 39.178970  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.848248 \tF1-score: 0.605550\n",
      "Epoch: 54 \tTraining Loss: 35.833917 \tValidation Loss: 36.843721  \tTesting Loss: 37.688684  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.640487 \tF1-score: 0.537065\n",
      "Epoch: 55 \tTraining Loss: 35.909256 \tValidation Loss: 36.030592  \tTesting Loss: 38.100986  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.642554 \tF1-score: 0.541980\n",
      "Epoch: 56 \tTraining Loss: 35.399080 \tValidation Loss: 36.229559  \tTesting Loss: 37.571869  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.629579 \tF1-score: 0.541654\n",
      "Epoch: 57 \tTraining Loss: 35.916473 \tValidation Loss: 36.440210  \tTesting Loss: 38.510433  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.648587 \tF1-score: 0.539224\n",
      "Epoch: 58 \tTraining Loss: 36.809570 \tValidation Loss: 36.752508  \tTesting Loss: 36.649988  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.757311 \tF1-score: 0.625362\n",
      "Epoch: 59 \tTraining Loss: 35.905511 \tValidation Loss: 36.995877  \tTesting Loss: 37.618013  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.625712 \tF1-score: 0.553935\n",
      "Epoch: 60 \tTraining Loss: 36.930410 \tValidation Loss: 39.767430  \tTesting Loss: 39.856636  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.642235 \tF1-score: 0.565655\n",
      "Epoch: 61 \tTraining Loss: 37.277725 \tValidation Loss: 35.859326  \tTesting Loss: 41.220704  \n",
      "\t\tAccuracy: 0.945000 \tPrecision: 0.634291 \tF1-score: 0.532633\n",
      "Epoch: 62 \tTraining Loss: 41.357497 \tValidation Loss: 38.122708  \tTesting Loss: 36.905301  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.604954 \tF1-score: 0.533957\n",
      "Epoch: 63 \tTraining Loss: 40.464340 \tValidation Loss: 40.612446  \tTesting Loss: 40.028899  \n",
      "\t\tAccuracy: 0.942000 \tPrecision: 0.603568 \tF1-score: 0.536983\n",
      "Epoch: 64 \tTraining Loss: 37.977188 \tValidation Loss: 36.658103  \tTesting Loss: 39.259495  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.654971 \tF1-score: 0.538980\n",
      "Epoch: 65 \tTraining Loss: 36.423923 \tValidation Loss: 35.905824  \tTesting Loss: 37.258207  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.843815 \tF1-score: 0.619377\n",
      "Epoch: 66 \tTraining Loss: 35.715868 \tValidation Loss: 35.952275  \tTesting Loss: 37.151280  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.623631 \tF1-score: 0.537671\n",
      "Epoch: 67 \tTraining Loss: 34.962052 \tValidation Loss: 35.251897  \tTesting Loss: 36.016129  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.756360 \tF1-score: 0.606457\n",
      "Epoch: 68 \tTraining Loss: 35.220008 \tValidation Loss: 36.041750  \tTesting Loss: 36.890349  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.660349 \tF1-score: 0.552024\n",
      "Epoch: 69 \tTraining Loss: 35.321928 \tValidation Loss: 35.571027  \tTesting Loss: 36.221706  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.650525 \tF1-score: 0.567920\n",
      "Epoch: 70 \tTraining Loss: 34.725514 \tValidation Loss: 35.398539  \tTesting Loss: 35.835699  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.726285 \tF1-score: 0.610986\n",
      "Epoch: 71 \tTraining Loss: 34.775117 \tValidation Loss: 38.310319  \tTesting Loss: 37.505965  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.651392 \tF1-score: 0.586328\n",
      "Epoch: 72 \tTraining Loss: 34.771034 \tValidation Loss: 34.480349  \tTesting Loss: 37.059920  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.758840 \tF1-score: 0.663655\n",
      "Epoch: 73 \tTraining Loss: 34.164472 \tValidation Loss: 35.464426  \tTesting Loss: 35.963505  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.654022 \tF1-score: 0.588139\n",
      "Epoch: 74 \tTraining Loss: 34.810220 \tValidation Loss: 35.905628  \tTesting Loss: 36.276864  \n",
      "\t\tAccuracy: 0.952000 \tPrecision: 0.721787 \tF1-score: 0.662578\n",
      "Epoch: 75 \tTraining Loss: 34.460504 \tValidation Loss: 35.035117  \tTesting Loss: 36.768796  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.644969 \tF1-score: 0.557682\n",
      "Epoch: 76 \tTraining Loss: 34.463321 \tValidation Loss: 34.523259  \tTesting Loss: 37.412912  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.730010 \tF1-score: 0.598937\n",
      "Epoch: 77 \tTraining Loss: 34.051480 \tValidation Loss: 33.977057  \tTesting Loss: 36.954525  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.760766 \tF1-score: 0.632784\n",
      "Epoch: 78 \tTraining Loss: 33.599143 \tValidation Loss: 35.169433  \tTesting Loss: 35.587504  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.737568 \tF1-score: 0.635201\n",
      "Epoch: 79 \tTraining Loss: 34.039070 \tValidation Loss: 33.880796  \tTesting Loss: 36.000601  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.734673 \tF1-score: 0.607250\n",
      "Epoch: 80 \tTraining Loss: 34.058276 \tValidation Loss: 34.756647  \tTesting Loss: 36.318622  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.722213 \tF1-score: 0.596731\n",
      "Epoch: 81 \tTraining Loss: 33.359979 \tValidation Loss: 35.711843  \tTesting Loss: 36.218084  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.723058 \tF1-score: 0.614324\n",
      "Epoch: 82 \tTraining Loss: 34.182638 \tValidation Loss: 33.871713  \tTesting Loss: 34.811462  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.776504 \tF1-score: 0.675982\n",
      "Epoch: 83 \tTraining Loss: 32.991372 \tValidation Loss: 34.795670  \tTesting Loss: 35.897151  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.710363 \tF1-score: 0.602974\n",
      "Epoch: 84 \tTraining Loss: 33.176112 \tValidation Loss: 35.750906  \tTesting Loss: 35.530087  \n",
      "\t\tAccuracy: 0.955000 \tPrecision: 0.761034 \tF1-score: 0.651802\n",
      "Epoch: 85 \tTraining Loss: 33.525615 \tValidation Loss: 33.857479  \tTesting Loss: 36.792700  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.744591 \tF1-score: 0.633536\n",
      "Epoch: 86 \tTraining Loss: 33.018521 \tValidation Loss: 34.270449  \tTesting Loss: 36.502140  \n",
      "\t\tAccuracy: 0.951000 \tPrecision: 0.762935 \tF1-score: 0.614195\n",
      "Epoch: 87 \tTraining Loss: 33.249956 \tValidation Loss: 37.165831  \tTesting Loss: 39.090003  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.687185 \tF1-score: 0.622800\n",
      "Epoch: 88 \tTraining Loss: 34.951122 \tValidation Loss: 36.064479  \tTesting Loss: 37.211645  \n",
      "\t\tAccuracy: 0.948000 \tPrecision: 0.732940 \tF1-score: 0.591743\n",
      "Epoch: 89 \tTraining Loss: 33.719212 \tValidation Loss: 33.306139  \tTesting Loss: 36.488093  \n",
      "\t\tAccuracy: 0.953000 \tPrecision: 0.786446 \tF1-score: 0.682560\n",
      "Epoch: 90 \tTraining Loss: 33.502081 \tValidation Loss: 33.607856  \tTesting Loss: 35.697492  \n",
      "\t\tAccuracy: 0.954000 \tPrecision: 0.759927 \tF1-score: 0.650602\n",
      "Epoch: 91 \tTraining Loss: 32.392508 \tValidation Loss: 33.882603  \tTesting Loss: 35.703568  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.718615 \tF1-score: 0.608497\n",
      "Epoch: 92 \tTraining Loss: 32.247271 \tValidation Loss: 34.737013  \tTesting Loss: 37.238309  \n",
      "\t\tAccuracy: 0.949000 \tPrecision: 0.717009 \tF1-score: 0.616045\n",
      "Epoch: 93 \tTraining Loss: 36.131497 \tValidation Loss: 39.365123  \tTesting Loss: 43.241478  \n",
      "\t\tAccuracy: 0.943000 \tPrecision: 0.656344 \tF1-score: 0.579439\n",
      "Epoch: 94 \tTraining Loss: 42.156106 \tValidation Loss: 38.948613  \tTesting Loss: 44.088743  \n",
      "\t\tAccuracy: 0.944000 \tPrecision: 0.606190 \tF1-score: 0.543075\n",
      "Epoch: 95 \tTraining Loss: 39.816571 \tValidation Loss: 38.752099  \tTesting Loss: 38.597802  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.631661 \tF1-score: 0.593297\n",
      "Epoch: 96 \tTraining Loss: 35.660420 \tValidation Loss: 34.849228  \tTesting Loss: 38.549023  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.705811 \tF1-score: 0.622782\n",
      "Epoch: 97 \tTraining Loss: 34.569431 \tValidation Loss: 36.319189  \tTesting Loss: 38.175435  \n",
      "\t\tAccuracy: 0.950000 \tPrecision: 0.751583 \tF1-score: 0.666534\n",
      "Epoch: 98 \tTraining Loss: 34.338524 \tValidation Loss: 34.348793  \tTesting Loss: 38.254372  \n",
      "\t\tAccuracy: 0.946000 \tPrecision: 0.673761 \tF1-score: 0.588597\n",
      "Epoch: 99 \tTraining Loss: 33.262221 \tValidation Loss: 33.722625  \tTesting Loss: 36.594335  \n",
      "\t\tAccuracy: 0.947000 \tPrecision: 0.675832 \tF1-score: 0.588135\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings (\"ignore\")\n",
    "for epoch in range(_n_epoch):\n",
    "    \n",
    "    if epoch == 0:\n",
    "        acc, prec, f1 = compute_acc(model, test_data_loader, labels=[0, 1, 2, 3, 4])\n",
    "        print('ðŸŒŸðŸŒŸðŸŒŸ Zero-shot Result: \\tAccuracy: {:.6f} \\tPrecision: {:.6f} \\tF1-score: {:.6f}'.format(\n",
    "            acc, prec, f1\n",
    "        ))\n",
    "    \n",
    "    train_loss = 0\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data_t, target = data[0].cuda(), data[1].reshape(_batch_size)\n",
    "        o_ = model(data_t)\n",
    "        loss = criterion(torch.log(o_), target.cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * _batch_size\n",
    "        \n",
    "    epoch_train_loss = train_loss / len(train_data_loader)\n",
    "    \n",
    "    epoch_verify_loss = compute_ave_batch_loss(model, verify_data_loader, criterion)\n",
    "    \n",
    "    epoch_test_loss = compute_ave_batch_loss(model, test_data_loader, criterion)\n",
    "    \n",
    "    acc, prec, f1 = compute_acc(model, test_data_loader, labels=[0, 1, 2, 3, 4])\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}  \\tTesting Loss: {:.6f} '\n",
    "         ' \\n\\t\\tAccuracy: {:.6f} \\tPrecision: {:.6f} \\tF1-score: {:.6f}'.format(\n",
    "        epoch, \n",
    "        epoch_train_loss,\n",
    "        epoch_verify_loss,\n",
    "        epoch_test_loss,\n",
    "        acc, prec, f1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2c268-5fd9-4821-b651-b03e3b39340b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}